{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from IPython.core.debugger import prompt\n",
    "from autorag.data.legacy.corpus import llama_text_node_to_parquet\n",
    "from autorag.data.legacy.qacreation import make_single_content_qa, generate_qa_llama_index\n",
    "from autorag.utils import cast_corpus_dataset\n",
    "from gitdb.fun import chunk_size\n",
    "from llama_index.legacy.llms import OpenAI\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T00:49:31.381323Z",
     "start_time": "2024-12-05T00:49:26.612912Z"
    }
   },
   "cell_type": "code",
   "source": "from autorag.utils.preprocess import cast_corpus_dataset ",
   "id": "ad18832a7abf4e0a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m[12/05/24 09:49:30]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m \u001B[1m[\u001B[0mconfig.py:\u001B[1;36m58\u001B[0m\u001B[1m]\u001B[0m >> PyTorch version \u001B[1;36m2.5\u001B[0m.\u001B[1;36m1\u001B[0m+cu124 available.                  \u001B]8;id=30093;file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\datasets\\config.py\u001B\\\u001B[2mconfig.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=634411;file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\datasets\\config.py#58\u001B\\\u001B[2m58\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/05/24 09:49:30] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>config.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span><span style=\"font-weight: bold\">]</span> &gt;&gt; PyTorch version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.5</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>+cu124 available.                  <a href=\"file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\datasets\\config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\datasets\\config.py#58\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">58</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_id\" in DeployedModel has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_kwargs\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPI has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in TextGenerationInference has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T00:49:43.233027Z",
     "start_time": "2024-12-05T00:49:31.381323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "documents = SimpleDirectoryReader(\"../data/genesis/\", recursive=True).load_data()"
   ],
   "id": "2c83562aca14afd1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T00:49:44.432983Z",
     "start_time": "2024-12-05T00:49:43.342128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from autorag.data.legacy.corpus.llama_index import llama_text_node_to_parquet\n",
    "nodes = TokenTextSplitter().get_nodes_from_documents(documents=documents, chunk_size=256, chunk_overlap=64)\n",
    "corpus_df = llama_text_node_to_parquet(nodes)\n",
    "corpus_df = cast_corpus_dataset(corpus_df)\n",
    "corpus_df.to_parquet('../data/test_dataset/corpus_new.parquet')"
   ],
   "id": "4f2de746fd01fa8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 질문생성",
   "id": "aa6ab39727969f9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T00:49:46.524110Z",
     "start_time": "2024-12-05T00:49:46.518151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ],
   "id": "e1f928c08a570138",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T00:49:47.498849Z",
     "start_time": "2024-12-05T00:49:47.488390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "24bf619e63e167bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T00:50:11.930229Z",
     "start_time": "2024-12-05T00:50:11.921390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"\"\"다음을 참고로 제네시스 차량 매뉴얼에 관한 내용을 만들었습니다.\n",
    "매뉴얼을 보고 할 만한 질문을 만드세요.\n",
    "반드시 제네시스 차량과 관련한 질문이어야 합니다.\n",
    "만약 주어진 매뉴얼 내용이 제네시스 차량과 관련되지 않았다면,\n",
    "'제네시스 차량과 관련 없었습니다.'라고 질문을 만드세요.\n",
    "\n",
    "매뉴얼:\n",
    "{{text}}\n",
    "\n",
    "생성할 질문 개수: {{num_questions}}\n",
    "\n",
    "예시:\n",
    "[Q]: 제네시스 차량의 타이어 공기압은 얼마인가요?\n",
    "[A]: 제네시스 차량의 타이어 공기압은 35 PSI입니다.\n",
    "\n",
    "제네시스 차량과 관련이 없는 매뉴얼의 경우 예시:\n",
    "[Q]: 제네시스 차량과 관련 없었습니다.\n",
    "[A]: 제네시스 차량과 관련 없었습니다.\n",
    "\"\"\""
   ],
   "id": "aafd58a092cd9fba",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T00:50:57.338671Z",
     "start_time": "2024-12-05T00:50:49.389459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from autorag.data.legacy.qacreation import make_single_content_qa, generate_qa_llama_index\n",
    "\n",
    "corpus_df = pd.read_parquet('../data/test_dataset/corpus_new.parquet', engine='pyarrow')\n",
    "llm = OpenAI(model='gpt-4o-mini', temperature=0.5)\n",
    "\n",
    "qa_df = make_single_content_qa(corpus_df=corpus_df, content_size=10, qa_creation_func=generate_qa_llama_index,\n",
    "                               llm=llm, prompt=prompt, question_num_per_content=2)"
   ],
   "id": "364795eee964788e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m[12/05/24 09:50:52]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m \u001B[1m[\u001B[0m_client.py:\u001B[1;36m1773\u001B[0m\u001B[1m]\u001B[0m >> HTTP Request: \u001B[1;33mPOST\u001B[0m                                \u001B]8;id=667574;file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py\u001B\\\u001B[2m_client.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=996218;file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py#1773\u001B\\\u001B[2m1773\u001B[0m\u001B]8;;\u001B\\\n",
       "\u001B[2;36m                    \u001B[0m         \u001B[4;94mhttps://api.openai.com/v1/chat/completions\u001B[0m \u001B[32m\"HTTP/1.1 200 OK\"\u001B[0m           \u001B[2m               \u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/05/24 09:50:52] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>_client.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1773</span><span style=\"font-weight: bold\">]</span> &gt;&gt; HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                <a href=\"file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py#1773\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1773</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m[12/05/24 09:50:53]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m \u001B[1m[\u001B[0m_client.py:\u001B[1;36m1773\u001B[0m\u001B[1m]\u001B[0m >> HTTP Request: \u001B[1;33mPOST\u001B[0m                                \u001B]8;id=199549;file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py\u001B\\\u001B[2m_client.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=70450;file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py#1773\u001B\\\u001B[2m1773\u001B[0m\u001B]8;;\u001B\\\n",
       "\u001B[2;36m                    \u001B[0m         \u001B[4;94mhttps://api.openai.com/v1/chat/completions\u001B[0m \u001B[32m\"HTTP/1.1 200 OK\"\u001B[0m           \u001B[2m               \u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/05/24 09:50:53] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>_client.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1773</span><span style=\"font-weight: bold\">]</span> &gt;&gt; HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                <a href=\"file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py#1773\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1773</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m \u001B[1m[\u001B[0m_client.py:\u001B[1;36m1773\u001B[0m\u001B[1m]\u001B[0m >> HTTP Request: \u001B[1;33mPOST\u001B[0m                                \u001B]8;id=313510;file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py\u001B\\\u001B[2m_client.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=200821;file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py#1773\u001B\\\u001B[2m1773\u001B[0m\u001B]8;;\u001B\\\n",
       "\u001B[2;36m                    \u001B[0m         \u001B[4;94mhttps://api.openai.com/v1/chat/completions\u001B[0m \u001B[32m\"HTTP/1.1 200 OK\"\u001B[0m           \u001B[2m               \u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>_client.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1773</span><span style=\"font-weight: bold\">]</span> &gt;&gt; HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                <a href=\"file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py#1773\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1773</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m[12/05/24 09:50:54]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m \u001B[1m[\u001B[0m_client.py:\u001B[1;36m1773\u001B[0m\u001B[1m]\u001B[0m >> HTTP Request: \u001B[1;33mPOST\u001B[0m                                \u001B]8;id=820180;file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py\u001B\\\u001B[2m_client.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=957035;file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py#1773\u001B\\\u001B[2m1773\u001B[0m\u001B]8;;\u001B\\\n",
       "\u001B[2;36m                    \u001B[0m         \u001B[4;94mhttps://api.openai.com/v1/chat/completions\u001B[0m \u001B[32m\"HTTP/1.1 200 OK\"\u001B[0m           \u001B[2m               \u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/05/24 09:50:54] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>_client.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1773</span><span style=\"font-weight: bold\">]</span> &gt;&gt; HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                <a href=\"file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py#1773\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1773</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m[12/05/24 09:50:57]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m \u001B[1m[\u001B[0m_client.py:\u001B[1;36m1773\u001B[0m\u001B[1m]\u001B[0m >> HTTP Request: \u001B[1;33mPOST\u001B[0m                                \u001B]8;id=456684;file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py\u001B\\\u001B[2m_client.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=562354;file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py#1773\u001B\\\u001B[2m1773\u001B[0m\u001B]8;;\u001B\\\n",
       "\u001B[2;36m                    \u001B[0m         \u001B[4;94mhttps://api.openai.com/v1/chat/completions\u001B[0m \u001B[32m\"HTTP/1.1 200 OK\"\u001B[0m           \u001B[2m               \u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/05/24 09:50:57] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>_client.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1773</span><span style=\"font-weight: bold\">]</span> &gt;&gt; HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                <a href=\"file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://E:\\TailorLink\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\httpx\\_client.py#1773\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1773</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.93s/it]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T00:51:03.974131Z",
     "start_time": "2024-12-05T00:51:03.964044Z"
    }
   },
   "cell_type": "code",
   "source": "qa_df.to_parquet('../data/test_dataset/corpus_new_test.parquet')",
   "id": "239652a122c7f2d7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "71e24b0157482249",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
