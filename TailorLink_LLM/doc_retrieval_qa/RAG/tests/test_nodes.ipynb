{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "990bfb8a24404644",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_teddynote import logging\n",
    "logging.langsmith('test_node')"
   ],
   "id": "1463938f091dbfd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 제네시스 관련 질문 판단 노드 함수",
   "id": "29f5b7e7d30496df"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from RAG.types import State\n",
    "from langgraph.graph import START, END\n",
    "from RAG.llm.prompt_templates import get_genesis_manual_classification_prompt\n",
    "from RAG.llm.model import get_OpenAI"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are an expert in Genesis Q&A.  \n",
    "        Determine whether the user's question is related to 'Genesis' or general vehicle usage and maintenance.  \n",
    "        \n",
    "        Criteria:  \n",
    "        - If the question mentions 'Genesis' vehicles or models (e.g., G70, G80, G90) and asks about usage, maintenance, functionality, update methods, or other manual-related inquiries, answer \"yes.\"  \n",
    "        - If the question does not explicitly mention 'Genesis' but refers to general vehicle usage, maintenance, or functionality that could apply to any vehicle, including 'Genesis,' answer \"yes.\"  \n",
    "        - If the question is unrelated to vehicles or does not fit the above criteria, answer \"no.\"  \n",
    "        \n",
    "        Assume that general vehicle-related questions (e.g., how to start a car, how to check oil) are indirectly relevant to 'Genesis' unless explicitly stated otherwise.  \n",
    "        \n",
    "        Your answer must be in English, and it should be either \"yes\" or \"no.\"  \n",
    "        \n",
    "        #Question:  \n",
    "        {question}  \n",
    "        \n",
    "        #Answer:\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "    )"
   ],
   "id": "3a28417512077d31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# prompt = get_genesis_manual_classification_prompt()\n",
    "llm = get_OpenAI()\n"
   ],
   "id": "9c873377b7aa2762",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"question\":'시동거는 법?'})\n",
    "\n",
    "print(response)"
   ],
   "id": "c11cbc539fac10ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 벡터DB 조회 노드 함수",
   "id": "9fdd957a58d218cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from RAG.types import State\n",
    "from langgraph.graph import START, END\n",
    "from RAG.llm.prompt_templates import get_genesis_manual_classification_prompt\n",
    "from RAG.llm.model import get_OpenAI"
   ],
   "id": "dd5d1e3ad7f0710f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        너는 전문적인 사용자 도우미이며, 주어진 CONTEXT를 기반으로 사용자의 질문에 대한 정확하고 상세한 답변을 작성해야 한다.  \n",
    "        답변은 한글로 작성하며, 마크다운 형식을 사용해 가독성을 높여야 한다.  \n",
    "        답변에는 항상 정보의 출처를 명시하며, CONTEXT를 통해 제공된 정보를 우선적으로 활용해야 한다.  \n",
    "        필요한 경우, 추가적인 예시나 세부 정보를 포함해 사용자의 질문에 완벽하게 답변하라.  \n",
    "        \n",
    "        # Context:  \n",
    "        {context}\n",
    "        \n",
    "        # Question:  \n",
    "        {question}  \n",
    "        \n",
    "        # Answer:  \n",
    "        ### 질문에 대한 답변:  \n",
    "        질문에 대한 구체적인 답변 작성\n",
    "        \n",
    "        ### 출처:  \n",
    "        1. CONTEXT 기반 정보: CONTEXT에서 관련된 정보 요약  \n",
    "\n",
    "        \"\"\"\n",
    "    )"
   ],
   "id": "775c8191602cfcb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm = get_OpenAI()",
   "id": "a7570628561f6934",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from RAG.database.milvus_connector import connect_to_milvus, get_collection\n",
    "connect_to_milvus()\n",
    "collection = get_collection('manual')"
   ],
   "id": "1e5570ab1659f052",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from milvus_model.hybrid import BGEM3EmbeddingFunction\n",
    "\n",
    "ef = BGEM3EmbeddingFunction(use_fp16=False, device=\"cpu\")"
   ],
   "id": "926f015a454dc04b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "query_embeddings = ef(['시동 켜는법?'])",
   "id": "874a0e1fcd9bc227",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ],
   "id": "74df570dc2e7322a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# !pip install langchain_milvus",
   "id": "aeb3acc896651225",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pymilvus import (\n",
    "    AnnSearchRequest,\n",
    "    WeightedRanker,\n",
    ")\n",
    "\n",
    "\n",
    "def dense_search(col, query_dense_embedding, limit=10):\n",
    "    search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
    "    res = col.search(\n",
    "        [query_dense_embedding],\n",
    "        anns_field=\"dense_vector\",\n",
    "        limit=limit,\n",
    "        output_fields=[\"text\"],\n",
    "        param=search_params,\n",
    "    )[0]\n",
    "    return [hit.get(\"text\") for hit in res]\n",
    "\n",
    "\n",
    "def sparse_search(col, query_sparse_embedding, limit=10):\n",
    "    search_params = {\n",
    "        \"metric_type\": \"IP\",\n",
    "        \"params\": {},\n",
    "    }\n",
    "    res = col.search(\n",
    "        [query_sparse_embedding],\n",
    "        anns_field=\"sparse_vector\",\n",
    "        limit=limit,\n",
    "        output_fields=[\"text\"],\n",
    "        param=search_params,\n",
    "    )[0]\n",
    "    return [hit.get(\"text\") for hit in res]\n",
    "\n",
    "\n",
    "def hybrid_search(\n",
    "    col,\n",
    "    query_dense_embedding,\n",
    "    query_sparse_embedding,\n",
    "    sparse_weight=1.0,\n",
    "    dense_weight=1.0,\n",
    "    limit=10,\n",
    "):\n",
    "    dense_search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
    "    dense_req = AnnSearchRequest(\n",
    "        [query_dense_embedding], \"dense_vector\", dense_search_params, limit=limit\n",
    "    )\n",
    "    sparse_search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
    "    sparse_req = AnnSearchRequest(\n",
    "        [query_sparse_embedding], \"sparse_vector\", sparse_search_params, limit=limit\n",
    "    )\n",
    "    rerank = WeightedRanker(sparse_weight, dense_weight)\n",
    "    res = col.hybrid_search(\n",
    "        [sparse_req, dense_req], rerank=rerank, limit=limit, output_fields=[\"text\"]\n",
    "    )[0]\n",
    "    return [hit.get(\"text\") for hit in res]"
   ],
   "id": "518390e1cdb4d08c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dense_results = dense_search(collection, query_embeddings[\"dense\"][0])\n",
    "sparse_results = sparse_search(collection, query_embeddings[\"sparse\"]._getrow(0))\n",
    "hybrid_results = hybrid_search(\n",
    "    collection,\n",
    "    query_embeddings[\"dense\"][0],\n",
    "    query_embeddings[\"sparse\"]._getrow(0),\n",
    "    sparse_weight=0.7,\n",
    "    dense_weight=1.0,\n",
    ")\n"
   ],
   "id": "3633fa425df082d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "retriever=vector_store_loaded.as_retriever(search_kwargs={\"expr\": 'namespace == \"ankush\"'})",
   "id": "384db626f7ff2e10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "retriever.invoke('시동')",
   "id": "e574df1d5d99f9b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = {\"context\": retriever, \"question\": RunnablePassthrough()}|prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"question\":'시동거는 법?'})\n",
    "\n"
   ],
   "id": "c47cfd2c100a9320",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e9c477a1a531f812",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from RAG.llm.prompt_templates import get_genesis_manual_classification_prompt, get_answer_with_context_prompt\n",
    "from RAG.llm.model import get_OpenAI\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ],
   "id": "5d37ab7dde09477e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from RAG.tools.tools import search_milvus"
   ],
   "id": "b1d9f00aa5442ccf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from RAG.types import State\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough"
   ],
   "id": "2bc329c2ebcaaaaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = '시동켜는법?'\n",
    "context = search_milvus(query)\n",
    "prompt = get_answer_with_context_prompt()\n",
    "llm = get_OpenAI()\n",
    "\n"
   ],
   "id": "1134e8e581a3873a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "prompt.invoke({'context': context, 'question': '시동'})",
   "id": "33a733bbceb79f33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4c7c6c7ca29b8aa4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        너는 전문적인 사용자 도우미이며, 주어진 CONTEXT만을 가지고 사용자의 질문에 대한 정확하고 상세한 답변을 작성해야 한다.  \n",
    "        답변은 한글로 작성하며, 마크다운 형식을 사용해 가독성을 높여야 한다.  \n",
    "        답변에는 항상 정보의 출처를 명시하며, CONTEXT를 통해 제공된 정보를 우선적으로 활용해야 한다.  \n",
    "        필요한 경우, 추가적인 예시나 세부 정보를 포함해 사용자의 질문에 완벽하게 답변하라.  \n",
    "        \n",
    "        # Context:  \n",
    "        {context}\n",
    "        \n",
    "        # Question:  \n",
    "        {question}  \n",
    "        \n",
    "        # Answer:  \n",
    "        ### 질문에 대한 답변:  \n",
    "        질문에 대한 구체적인 답변 작성\n",
    "        \n",
    "        ### 출처:  \n",
    "        1. CONTEXT 기반 정보: CONTEXT에서 관련된 정보 요약  \n",
    "\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "# context_list = '\\n'.join(context)\n",
    "# \n",
    "# pp = ({'context': context_list, 'question': RunnablePassthrough()} | prompt)"
   ],
   "id": "549297295f87c7c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "pt = {\"context\": context, \"question\": RunnablePassthrough()} | prompt\n",
    "\n",
    "# 데이터를 실행\n",
    "output = pt.invoke({\"question\": \"tlehd\"})\n",
    "print(output)"
   ],
   "id": "ebee5a79b21be324",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "pt =  prompt\n",
    "\n",
    "# 실행\n",
    "output = pt.invoke({\"context\": context, \"question\": '시동'})"
   ],
   "id": "e5a33130198ca957",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "chain = prompt | llm | StrOutputParser()\n",
    "output = chain.invoke({\"context\": context, \"question\": '경고등이 울리는데 왜 이래?'})\n"
   ],
   "id": "7d794340b6a52c57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(output)",
   "id": "3236c7db307e3a29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a9f45536a80b592d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7fc5aa3e70fdae12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "742489f116033d05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 답변 점수 측정 노드",
   "id": "58534cc68da37201"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from RAG.llm.prompt_templates import get_genesis_manual_classification_prompt, get_answer_with_context_prompt\n",
    "from RAG.llm.model import get_OpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ],
   "id": "42912ebb79968243",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        너는 전문적인 사용자 도우미이며, 주어진 Question과 Answer를 가지고 Answer가 사용자가 원하는 답인지 점수를 계산해야 한다.  \n",
    "        점수를 계산할 때, Answer가 주어진 Context외의 정보를 가지고 있으면 안된다.\n",
    "        JSON 형식 Reason과 Score로 대답해라.\n",
    "        # Context:  \n",
    "        {context}\n",
    "        \n",
    "        # Question:  \n",
    "        {question}  \n",
    "        \n",
    "        # Answer:  \n",
    "        {answer}\n",
    "        \n",
    "        {{\n",
    "          \"reason\": \"value1\",\n",
    "          \"score\": 100\n",
    "        }}     \n",
    "        \"\"\"\n",
    "    )"
   ],
   "id": "ffcf867ac8b885e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "prompt.input_variables",
   "id": "f377a4e85aceaa9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm = get_OpenAI()",
   "id": "21fedbc455538be1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from RAG.tools.tools import search_milvus\n",
    "from RAG.database.milvus_connector import connect_to_milvus, get_collection\n",
    "connect_to_milvus()\n",
    "collection = get_collection('manual')\n",
    "query = '시동켜는법?'\n",
    "context = search_milvus(query)"
   ],
   "id": "dd39b78f2a15cd83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "# 사용자의 질문에 대한 답변\n",
    "response_schemas = [\n",
    "    ResponseSchema(\n",
    "        name=\"score\",\n",
    "        description=\"질문에 대한 점수, 숫자여햐 한다.\",\n",
    "    ),\n",
    "    ResponseSchema(name=\"reason\", description=\"점수를 제외한 나머지 \"),\n",
    "]\n",
    "# 응답 스키마를 기반으로 한 구조화된 출력 파서 초기화\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ],
   "id": "8ab9ed1200f9dd60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chain = prompt | llm | output_parser",
   "id": "edfe0c8ac3ee770c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "answer = \"\"\"\n",
    "\n",
    "    ### 질문에 대한 답변:  \n",
    "    경고등이 울리는 이유는 여러 가지가 있을 수 있습니다. 일반적으로 경고등은 차량의 시스템에서 문제가 발생했음을 알리는 신호입니다. 다음은 경고등이 울릴 수 있는 몇 가지 일반적인 원인입니다:\n",
    "    \n",
    "    1. **브레이크 시스템 문제**: 브레이크 페달을 밟지 않고 시동 버튼을 누르면 시동이 걸리지 않거나 경고등이 켜질 수 있습니다. 브레이크 시스템에 문제가 있을 경우 경고등이 울릴 수 있습니다.\n",
    "    \n",
    "    2. **기어 상태**: 기어가 'P'(주차) 또는 'N'(중립) 상태가 아닐 경우, 시동이 걸리지 않거나 경고음이 발생할 수 있습니다. 차량이 주행 중일 때 기어를 잘못 조작하면 경고등이 울릴 수 있습니다.\n",
    "    \n",
    "    3. **스마트 키 문제**: 스마트 키의 배터리가 방전되었거나 차량 내부에 스마트 키가 없을 경우 경고등이 울릴 수 있습니다. 이 경우, 스마트 키가 차량에 있는지 확인해야 합니다.\n",
    "    \n",
    "    4. **엔진 상태**: 엔진이 정지하기 직전에는 고속 공회전을 삼가야 하며, 이로 인해 경고등이 울릴 수 있습니다. 엔진이 비정상적으로 작동할 경우 경고등이 켜질 수 있습니다.\n",
    "    \n",
    "    5. **전자식 파킹 브레이크**: 전자식 파킹 브레이크가 제대로 작동하지 않으면 경고등이 울릴 수 있습니다. 이 경우, 파킹 브레이크 스위치를 확인해야 합니다.\n",
    "    \n",
    "    경고등이 울릴 경우, 차량의 매뉴얼을 참조하거나 가까운 정비소에 문의하여 정확한 원인을 파악하고 조치를 취하는 것이 중요합니다.\n",
    "    \n",
    "    ### 출처:  \n",
    "    1. CONTEXT 기반 정보: 차량의 시동 및 주행 관련 정보, 경고등 및 시스템 문제에 대한 설명.\n",
    "\"\"\""
   ],
   "id": "78f423446c7f4f53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# query = '시동켜는법?'\n",
    "query = '경고등이 울리는데 왜 이래?'\n",
    "context = search_milvus(query)\n",
    "\n",
    "res= chain.invoke({\"context\": context, \"question\": query, \"answer\": answer})"
   ],
   "id": "95dcf3a175e08eb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(res)",
   "id": "f9aebb06ce7378e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res['score']",
   "id": "5371ae36d9e4a437",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "16e5b4d167787880",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rewrite_query(query, llm):\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"query\"],\n",
    "        template=\"Rewrite the query '{query}' to improve retrieval quality.\"\n",
    "    )\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    return chain.run(query)"
   ],
   "id": "efdfe1dbbd6c6108",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Rewrite the query '{question}' to improve retrieval quality. Use the context of previous questions and generate only one improved query. Ensure the new query does not overlap with any of the previous questions.\n",
    "\n",
    "        # Previous questions: \n",
    "        {previous}\n",
    "\n",
    "        \"\"\"\n",
    "    )"
   ],
   "id": "e6565a9e45e876c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm = get_OpenAI()",
   "id": "9c827c51a3877882",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chain = prompt | llm | StrOutputParser()",
   "id": "84f7fec11bf84eb5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = '시동 켜는 법'\n",
    "previous = ['자동차 시동 켜는 방법','시동을 켜는 절차']\n",
    "res = chain.invoke({'previous':previous,'question': query})\n",
    "res"
   ],
   "id": "9e6090f99a9beab6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:03:45.150745Z",
     "start_time": "2024-12-09T14:03:45.148638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from RAG.types import State \n",
    "a = State({\"message\":\"dfdf\"})"
   ],
   "id": "f5298308665375a6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:03:45.953684Z",
     "start_time": "2024-12-09T14:03:45.946766Z"
    }
   },
   "cell_type": "code",
   "source": "a['context']",
   "id": "764f013b199aa372",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'context'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43ma\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcontext\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'context'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "26bb426a9014920d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
