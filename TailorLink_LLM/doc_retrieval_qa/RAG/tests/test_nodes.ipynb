{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T07:04:23.545981Z",
     "start_time": "2024-12-10T07:04:23.531185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "990bfb8a24404644",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T07:04:23.636637Z",
     "start_time": "2024-12-10T07:04:23.632291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote import logging\n",
    "logging.langsmith('test_node')"
   ],
   "id": "1463938f091dbfd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "test_node\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 제네시스 관련 질문 판단 노드 함수",
   "id": "29f5b7e7d30496df"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from RAG.types import State\n",
    "from langgraph.graph import START, END\n",
    "from RAG.llm.prompt_templates import get_genesis_manual_classification_prompt\n",
    "from RAG.llm.model import get_OpenAI"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are an expert in Genesis Q&A.  \n",
    "        Determine whether the user's question is related to 'Genesis' or general vehicle usage and maintenance.  \n",
    "        \n",
    "        Criteria:  \n",
    "        - If the question mentions 'Genesis' vehicles or models (e.g., G70, G80, G90) and asks about usage, maintenance, functionality, update methods, or other manual-related inquiries, answer \"yes.\"  \n",
    "        - If the question does not explicitly mention 'Genesis' but refers to general vehicle usage, maintenance, or functionality that could apply to any vehicle, including 'Genesis,' answer \"yes.\"  \n",
    "        - If the question is unrelated to vehicles or does not fit the above criteria, answer \"no.\"  \n",
    "        \n",
    "        Assume that general vehicle-related questions (e.g., how to start a car, how to check oil) are indirectly relevant to 'Genesis' unless explicitly stated otherwise.  \n",
    "        \n",
    "        Your answer must be in English, and it should be either \"yes\" or \"no.\"  \n",
    "        \n",
    "        #Question:  \n",
    "        {question}  \n",
    "        \n",
    "        #Answer:\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "    )"
   ],
   "id": "3a28417512077d31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# prompt = get_genesis_manual_classification_prompt()\n",
    "llm = get_OpenAI()\n"
   ],
   "id": "9c873377b7aa2762",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"question\":'시동거는 법?'})\n",
    "\n",
    "print(response)"
   ],
   "id": "c11cbc539fac10ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 벡터DB 조회 노드 함수",
   "id": "9fdd957a58d218cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:33:52.879181Z",
     "start_time": "2024-12-10T08:33:52.348137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from RAG.types import State\n",
    "from langgraph.graph import START, END\n",
    "from RAG.llm.prompt_templates import get_genesis_manual_classification_prompt\n",
    "from RAG.llm.model import get_OpenAI"
   ],
   "id": "dd5d1e3ad7f0710f",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:33:52.891017Z",
     "start_time": "2024-12-10T08:33:52.886567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        너는 전문적인 사용자 도우미이며, 주어진 CONTEXT를 기반으로 사용자의 질문에 대한 정확하고 상세한 답변을 작성해야 한다.  \n",
    "        답변은 한글로 작성하며, 마크다운 형식을 사용해 가독성을 높여야 한다.  \n",
    "        답변에는 항상 정보의 출처를 명시하며, CONTEXT를 통해 제공된 정보를 우선적으로 활용해야 한다.  \n",
    "        필요한 경우, 추가적인 예시나 세부 정보를 포함해 사용자의 질문에 완벽하게 답변하라.  \n",
    "        \n",
    "        # Context:  \n",
    "        {context}\n",
    "        \n",
    "        # Question:  \n",
    "        {question}  \n",
    "        \n",
    "        # Answer:  \n",
    "        ### 질문에 대한 답변:  \n",
    "        질문에 대한 구체적인 답변 작성\n",
    "        \n",
    "        ### 출처:  \n",
    "        1. CONTEXT 기반 정보: CONTEXT에서 관련된 정보 요약  \n",
    "\n",
    "        \"\"\"\n",
    "    )"
   ],
   "id": "775c8191602cfcb9",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:33:53.964395Z",
     "start_time": "2024-12-10T08:33:53.683305Z"
    }
   },
   "cell_type": "code",
   "source": "llm = get_OpenAI()",
   "id": "a7570628561f6934",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:33:56.054867Z",
     "start_time": "2024-12-10T08:33:54.363889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from RAG.database.milvus_connector import connect_to_milvus, get_collection\n",
    "connect_to_milvus()\n",
    "collection = get_collection('manual')"
   ],
   "id": "1e5570ab1659f052",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Milvus\n",
      "Connected to Milvus\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:34:16.016947Z",
     "start_time": "2024-12-10T08:33:56.136934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from milvus_model.hybrid import BGEM3EmbeddingFunction\n",
    "\n",
    "ef = BGEM3EmbeddingFunction(use_fp16=False, device=\"cpu\")"
   ],
   "id": "926f015a454dc04b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "121aa942207e466ab50a9f42444ec0b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:34:17.846783Z",
     "start_time": "2024-12-10T08:34:16.021529Z"
    }
   },
   "cell_type": "code",
   "source": "query_embeddings = ef(['시동 켜는법?'])",
   "id": "874a0e1fcd9bc227",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:34:18.133610Z",
     "start_time": "2024-12-10T08:34:17.852147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ],
   "id": "74df570dc2e7322a",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:34:18.140494Z",
     "start_time": "2024-12-10T08:34:18.138486Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip install langchain_milvus",
   "id": "aeb3acc896651225",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:34:18.149095Z",
     "start_time": "2024-12-10T08:34:18.144477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pymilvus import (\n",
    "    AnnSearchRequest,\n",
    "    WeightedRanker,\n",
    ")\n",
    "\n",
    "\n",
    "def dense_search(col, query_dense_embedding, limit=10):\n",
    "    search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
    "    res = col.search(\n",
    "        [query_dense_embedding],\n",
    "        anns_field=\"dense_vector\",\n",
    "        limit=limit,\n",
    "        output_fields=[\"text\"],\n",
    "        param=search_params,\n",
    "    )[0]\n",
    "    return [hit.get(\"text\") for hit in res]\n",
    "\n",
    "\n",
    "def sparse_search(col, query_sparse_embedding, limit=10):\n",
    "    search_params = {\n",
    "        \"metric_type\": \"IP\",\n",
    "        \"params\": {},\n",
    "    }\n",
    "    res = col.search(\n",
    "        [query_sparse_embedding],\n",
    "        anns_field=\"sparse_vector\",\n",
    "        limit=limit,\n",
    "        output_fields=[\"text\"],\n",
    "        param=search_params,\n",
    "    )[0]\n",
    "    return [hit.get(\"text\") for hit in res]\n",
    "\n",
    "\n",
    "def hybrid_search(\n",
    "    col,\n",
    "    query_dense_embedding,\n",
    "    query_sparse_embedding,\n",
    "    sparse_weight=1.0,\n",
    "    dense_weight=1.0,\n",
    "    limit=10,\n",
    "):\n",
    "    dense_search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
    "    dense_req = AnnSearchRequest(\n",
    "        [query_dense_embedding], \"dense_vector\", dense_search_params, limit=limit\n",
    "    )\n",
    "    sparse_search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
    "    sparse_req = AnnSearchRequest(\n",
    "        [query_sparse_embedding], \"sparse_vector\", sparse_search_params, limit=limit\n",
    "    )\n",
    "    rerank = WeightedRanker(sparse_weight, dense_weight)\n",
    "    res = col.hybrid_search(\n",
    "        [sparse_req, dense_req], rerank=rerank, limit=limit, output_fields=[\"text\"]\n",
    "    )[0]\n",
    "    return [hit.get(\"text\") for hit in res]"
   ],
   "id": "518390e1cdb4d08c",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:34:19.306959Z",
     "start_time": "2024-12-10T08:34:18.153272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dense_results = dense_search(collection, query_embeddings[\"dense\"][0])\n",
    "sparse_results = sparse_search(collection, query_embeddings[\"sparse\"]._getrow(0))\n",
    "hybrid_results = hybrid_search(\n",
    "    collection,\n",
    "    query_embeddings[\"dense\"][0],\n",
    "    query_embeddings[\"sparse\"]._getrow(0),\n",
    "    sparse_weight=0.7,\n",
    "    dense_weight=1.0,\n",
    ")\n"
   ],
   "id": "3633fa425df082d7",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T08:34:19.547519Z",
     "start_time": "2024-12-10T08:34:19.313178Z"
    }
   },
   "cell_type": "code",
   "source": "retriever=vector_store_loaded.as_retriever(search_kwargs={\"expr\": 'namespace == \"ankush\"'})",
   "id": "384db626f7ff2e10",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_store_loaded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[70], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m retriever\u001B[38;5;241m=\u001B[39m\u001B[43mvector_store_loaded\u001B[49m\u001B[38;5;241m.\u001B[39mas_retriever(search_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexpr\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnamespace == \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mankush\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m})\n",
      "\u001B[1;31mNameError\u001B[0m: name 'vector_store_loaded' is not defined"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "retriever.invoke('시동')",
   "id": "e574df1d5d99f9b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = {\"context\": retriever, \"question\": RunnablePassthrough()}|prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"question\":'시동거는 법?'})\n",
    "\n"
   ],
   "id": "c47cfd2c100a9320",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e9c477a1a531f812",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from RAG.llm.prompt_templates import get_genesis_manual_classification_prompt, get_answer_with_context_prompt\n",
    "from RAG.llm.model import get_OpenAI\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ],
   "id": "5d37ab7dde09477e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from RAG.tools.tools import search_milvus"
   ],
   "id": "b1d9f00aa5442ccf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from RAG.types import State\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough"
   ],
   "id": "2bc329c2ebcaaaaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = '시동켜는법?'\n",
    "context = search_milvus(query)\n",
    "prompt = get_answer_with_context_prompt()\n",
    "llm = get_OpenAI()\n",
    "\n"
   ],
   "id": "1134e8e581a3873a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "prompt.invoke({'context': context, 'question': '시동'})",
   "id": "33a733bbceb79f33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 답변 생성",
   "id": "4c7c6c7ca29b8aa4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        너는 전문적인 사용자 도우미이며, 주어진 CONTEXT만을 가지고 사용자의 질문에 대한 정확하고 상세한 답변을 작성해야 한다.  \n",
    "        답변은 한글로 작성하며, 마크다운 형식을 사용해 가독성을 높여야 한다.  \n",
    "        답변에는 항상 정보의 출처를 명시하며, CONTEXT를 통해 제공된 정보를 우선적으로 활용해야 한다.  \n",
    "        필요한 경우, 추가적인 예시나 세부 정보를 포함해 사용자의 질문에 완벽하게 답변하라.  \n",
    "        \n",
    "        # Context:  \n",
    "        {context}\n",
    "        \n",
    "        # Question:  \n",
    "        {question}  \n",
    "        \n",
    "        # Answer:  \n",
    "        ### 질문에 대한 답변:  \n",
    "        질문에 대한 구체적인 답변 작성\n",
    "        \n",
    "        ### 출처:  \n",
    "        1. CONTEXT 기반 정보: CONTEXT에서 관련된 정보 요약  \n",
    "\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "# context_list = '\\n'.join(context)\n",
    "# \n",
    "# pp = ({'context': context_list, 'question': RunnablePassthrough()} | prompt)"
   ],
   "id": "549297295f87c7c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "pt = {\"context\": context, \"question\": RunnablePassthrough()} | prompt\n",
    "\n",
    "# 데이터를 실행\n",
    "output = pt.invoke({\"question\": \"tlehd\"})\n",
    "print(output)"
   ],
   "id": "ebee5a79b21be324",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "pt =  prompt\n",
    "\n",
    "# 실행\n",
    "output = pt.invoke({\"context\": context, \"question\": '시동'})"
   ],
   "id": "e5a33130198ca957",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "chain = prompt | llm | StrOutputParser()\n",
    "output = chain.invoke({\"context\": context, \"question\": '경고등이 울리는데 왜 이래?'})\n"
   ],
   "id": "7d794340b6a52c57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(output)",
   "id": "3236c7db307e3a29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 답변 점수 측정 노드",
   "id": "58534cc68da37201"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from RAG.llm.prompt_templates import get_genesis_manual_classification_prompt, get_answer_with_context_prompt\n",
    "from RAG.llm.model import get_OpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ],
   "id": "42912ebb79968243",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        너는 전문적인 사용자 도우미이며, 주어진 Question과 Answer를 가지고 Answer가 사용자가 원하는 답인지 점수를 계산해야 한다.  \n",
    "        점수를 계산할 때, Answer가 주어진 Context외의 정보를 가지고 있으면 안된다.\n",
    "        JSON 형식 Reason과 Score로 대답해라.\n",
    "        # Context:  \n",
    "        {context}\n",
    "        \n",
    "        # Question:  \n",
    "        {question}  \n",
    "        \n",
    "        # Answer:  \n",
    "        {answer}\n",
    "        \n",
    "        {{\n",
    "          \"reason\": \"value1\",\n",
    "          \"score\": 100\n",
    "        }}     \n",
    "        \"\"\"\n",
    "    )"
   ],
   "id": "ffcf867ac8b885e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "prompt.input_variables",
   "id": "f377a4e85aceaa9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm = get_OpenAI()",
   "id": "21fedbc455538be1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from RAG.tools.tools import search_milvus\n",
    "from RAG.database.milvus_connector import connect_to_milvus, get_collection\n",
    "connect_to_milvus()\n",
    "collection = get_collection('manual')\n",
    "query = '시동켜는법?'\n",
    "context = search_milvus(query)"
   ],
   "id": "dd39b78f2a15cd83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "# 사용자의 질문에 대한 답변\n",
    "response_schemas = [\n",
    "    ResponseSchema(\n",
    "        name=\"score\",\n",
    "        description=\"질문에 대한 점수, 숫자여햐 한다.\",\n",
    "    ),\n",
    "    ResponseSchema(name=\"reason\", description=\"점수를 제외한 나머지 \"),\n",
    "]\n",
    "# 응답 스키마를 기반으로 한 구조화된 출력 파서 초기화\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ],
   "id": "8ab9ed1200f9dd60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chain = prompt | llm | output_parser",
   "id": "edfe0c8ac3ee770c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "answer = \"\"\"\n",
    "\n",
    "    ### 질문에 대한 답변:  \n",
    "    경고등이 울리는 이유는 여러 가지가 있을 수 있습니다. 일반적으로 경고등은 차량의 시스템에서 문제가 발생했음을 알리는 신호입니다. 다음은 경고등이 울릴 수 있는 몇 가지 일반적인 원인입니다:\n",
    "    \n",
    "    1. **브레이크 시스템 문제**: 브레이크 페달을 밟지 않고 시동 버튼을 누르면 시동이 걸리지 않거나 경고등이 켜질 수 있습니다. 브레이크 시스템에 문제가 있을 경우 경고등이 울릴 수 있습니다.\n",
    "    \n",
    "    2. **기어 상태**: 기어가 'P'(주차) 또는 'N'(중립) 상태가 아닐 경우, 시동이 걸리지 않거나 경고음이 발생할 수 있습니다. 차량이 주행 중일 때 기어를 잘못 조작하면 경고등이 울릴 수 있습니다.\n",
    "    \n",
    "    3. **스마트 키 문제**: 스마트 키의 배터리가 방전되었거나 차량 내부에 스마트 키가 없을 경우 경고등이 울릴 수 있습니다. 이 경우, 스마트 키가 차량에 있는지 확인해야 합니다.\n",
    "    \n",
    "    4. **엔진 상태**: 엔진이 정지하기 직전에는 고속 공회전을 삼가야 하며, 이로 인해 경고등이 울릴 수 있습니다. 엔진이 비정상적으로 작동할 경우 경고등이 켜질 수 있습니다.\n",
    "    \n",
    "    5. **전자식 파킹 브레이크**: 전자식 파킹 브레이크가 제대로 작동하지 않으면 경고등이 울릴 수 있습니다. 이 경우, 파킹 브레이크 스위치를 확인해야 합니다.\n",
    "    \n",
    "    경고등이 울릴 경우, 차량의 매뉴얼을 참조하거나 가까운 정비소에 문의하여 정확한 원인을 파악하고 조치를 취하는 것이 중요합니다.\n",
    "    \n",
    "    ### 출처:  \n",
    "    1. CONTEXT 기반 정보: 차량의 시동 및 주행 관련 정보, 경고등 및 시스템 문제에 대한 설명.\n",
    "\"\"\""
   ],
   "id": "78f423446c7f4f53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# query = '시동켜는법?'\n",
    "query = '경고등이 울리는데 왜 이래?'\n",
    "context = search_milvus(query)\n",
    "\n",
    "res= chain.invoke({\"context\": context, \"question\": query, \"answer\": answer})"
   ],
   "id": "95dcf3a175e08eb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(res)",
   "id": "f9aebb06ce7378e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res['score']",
   "id": "5371ae36d9e4a437",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 쿼리 재생성",
   "id": "6661de7c144d2241"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Rewrite the query '{question}' to improve retrieval quality. Use the context of previous questions and generate only one improved query. Ensure the new query does not overlap with any of the previous questions.\n",
    "\n",
    "        # Previous questions: \n",
    "        {previous}\n",
    "\n",
    "        \"\"\"\n",
    "    )"
   ],
   "id": "e6565a9e45e876c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm = get_OpenAI()",
   "id": "9c827c51a3877882",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chain = prompt | llm | StrOutputParser()",
   "id": "84f7fec11bf84eb5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = '시동 켜는 법'\n",
    "previous = ['자동차 시동 켜는 방법','시동을 켜는 절차']\n",
    "res = chain.invoke({'previous':previous,'question': query})\n",
    "res"
   ],
   "id": "9e6090f99a9beab6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:03:45.150745Z",
     "start_time": "2024-12-09T14:03:45.148638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from RAG.types import State \n",
    "a = State({\"message\":\"dfdf\"})"
   ],
   "id": "f5298308665375a6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:03:45.953684Z",
     "start_time": "2024-12-09T14:03:45.946766Z"
    }
   },
   "cell_type": "code",
   "source": "a['context']",
   "id": "764f013b199aa372",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'context'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43ma\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcontext\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'context'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 질문 분할 노드",
   "id": "b1865f449da5ae62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T07:22:39.692336Z",
     "start_time": "2024-12-10T07:22:39.690141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        너는 RAG 전문가이다.  \n",
    "        주어진 질문이 복합적인 내용으로 구성된 경우, 각 질문을 독립적인 단위로 분리해야 한다.  \n",
    "        질문을 분리할 때, 각 질문이 명확하고 RAG의 검색 및 답변 생성 품질이 최대화되도록 작성해야 한다.  \n",
    "        \n",
    "        ### 지침:\n",
    "        - 질문 분리는 논리적 흐름에 따라 자연스럽게 이루어져야 한다.\n",
    "        - 각 질문은 특정 주제나 개념에 집중하여 검색 가능한 형태로 작성해야 한다.\n",
    "        - 분리된 결과는 **리스트 형식**으로 반환하며, 추가 설명 없이 리스트만 출력해야 한다.\n",
    "        \n",
    "        ### 예시:  \n",
    "        입력: \"g90 시동 거는 방법과 스펙을 알려줘.\"  \n",
    "        출력: [\"g90의 시동 거는 방법은 무엇인가?\", \"g90의 스펙은 무엇인가?\"]\n",
    "                \n",
    "        질문을 분리한 결과를 항상 리스트 형태로만 반환하라.\n",
    "        \n",
    "        ### 입력 : {query}\n",
    "        ### 출력 :\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "    )"
   ],
   "id": "26bb426a9014920d",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T07:26:04.161028Z",
     "start_time": "2024-12-10T07:26:04.158605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt2 = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "You are an expert in RAG.  \n",
    "When presented with a compound question, you must split it into independent units.  \n",
    "Each split question should be clear and optimized to enhance the quality of RAG's retrieval and response generation.  \n",
    "\n",
    "### Instructions:\n",
    "- Split the questions naturally, following a logical flow.\n",
    "- Each question should focus on a specific topic or concept and be written in a searchable format.\n",
    "- The split results must be returned in **list format**, with no additional explanations—only the list itself.\n",
    "- The split questions **must be written in Korean**.\n",
    "\n",
    "### Example:  \n",
    "Input: \"How do I start a G90, and what are its specs?\"  \n",
    "Output: [\"g90의 시동 거는 방법은 무엇인가?\", \"g90의 스펙은 무엇인가?\"]\n",
    "\n",
    "Always return the split results in list format and in Korean.\n",
    "\n",
    "### Input: {query}  \n",
    "### Output:  \n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "    )"
   ],
   "id": "5e479f8f7fc115d",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T07:27:04.313430Z",
     "start_time": "2024-12-10T07:27:04.310812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from RAG.llm.model import get_OpenAI, get_ollama\n",
    "# llm = get_OpenAI()\n",
    "llm  = get_ollama('linkbricks-8B')"
   ],
   "id": "87983f602f2fec86",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T07:27:06.080622Z",
     "start_time": "2024-12-10T07:27:06.078465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt2 | llm | StrOutputParser()"
   ],
   "id": "6d3061c6305cfa76",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T07:27:08.901392Z",
     "start_time": "2024-12-10T07:27:06.460640Z"
    }
   },
   "cell_type": "code",
   "source": "chain.invoke({'query':'엔진오일은 언제 교체해야해.'})",
   "id": "f3fb951abcbbb6e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[안전 장치 종류는 무엇인가요?, 연료 타입은 무엇인가요?, 엔진 오일 교체 시기는 언제인가요?] '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T07:23:16.696896Z",
     "start_time": "2024-12-10T07:23:16.650847Z"
    }
   },
   "cell_type": "code",
   "source": "!ollama list",
   "id": "a1d7aa06f2184f71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                ID              SIZE      MODIFIED    \n",
      "linkbricks-8B:latest                                a2b5f952edbc    4.9 GB    12 days ago    \n",
      "llama3.2-vision:latest                              38107a0cd119    7.9 GB    2 weeks ago    \n",
      "llama3.2:latest                                     a80c4f17acd5    2.0 GB    2 weeks ago    \n",
      "bge-m3:latest                                       790764642607    1.2 GB    2 weeks ago    \n",
      "llama-3.2-ko:latest                                 61559401996a    2.0 GB    2 weeks ago    \n",
      "evee:latest                                         20b0eed63ec6    21 GB     2 weeks ago    \n",
      "bnksys/yanolja-eeve-korean-instruct-10.8b:latest    a3102004a8cd    11 GB     2 weeks ago    \n",
      "llama-3.2-korean-bllossom-3b:latest                 61559401996a    2.0 GB    2 weeks ago    \n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "721e0203554eb912"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e5fe5089e90dd29"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
