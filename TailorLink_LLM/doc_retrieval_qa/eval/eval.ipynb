{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# METEOR",
   "id": "a9ce3db66048a281"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-02T03:13:17.038821Z",
     "start_time": "2024-12-02T03:13:17.029722Z"
    }
   },
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalize the text by lowercasing and removing punctuation.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "def get_word_matches(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    Compute word matches between the reference and hypothesis.\n",
    "    \"\"\"\n",
    "    ref_words = reference.split()\n",
    "    hyp_words = hypothesis.split()\n",
    "\n",
    "    ref_counts = Counter(ref_words)\n",
    "    hyp_counts = Counter(hyp_words)\n",
    "\n",
    "    # Find intersection of words\n",
    "    matches = sum((ref_counts & hyp_counts).values())\n",
    "    return matches\n",
    "\n",
    "def compute_meteor_score(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    Compute the METEOR score for a single pair of reference and hypothesis.\n",
    "    \"\"\"\n",
    "    # Normalize texts\n",
    "    reference = normalize_text(reference)\n",
    "    hypothesis = normalize_text(hypothesis)\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    matches = get_word_matches(reference, hypothesis)\n",
    "    precision = matches / len(hypothesis.split()) if hypothesis.split() else 0\n",
    "    recall = matches / len(reference.split()) if reference.split() else 0\n",
    "\n",
    "    # Calculate F-measure\n",
    "    if precision + recall > 0:\n",
    "        f1_score = (10 * precision * recall) / (9 * precision + recall)\n",
    "    else:\n",
    "        f1_score = 0\n",
    "\n",
    "    # Apply penalty for word order mismatch\n",
    "    hyp_words = hypothesis.split()\n",
    "    ref_words = reference.split()\n",
    "    chunks = 0\n",
    "    i = 0\n",
    "    while i < len(hyp_words):\n",
    "        if hyp_words[i] in ref_words:\n",
    "            start_index = ref_words.index(hyp_words[i])\n",
    "            while i < len(hyp_words) and start_index < len(ref_words) and hyp_words[i] == ref_words[start_index]:\n",
    "                i += 1\n",
    "                start_index += 1\n",
    "            chunks += 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    penalty = 0.5 * (chunks / matches) if matches > 0 else 1\n",
    "    meteor_score = f1_score * (1 - penalty)\n",
    "\n",
    "    # Return the detailed metrics\n",
    "    return {\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": f1_score\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "reference_text = \"The quick brown fox jumps over the lazy dog\"\n",
    "hypothesis_text = \"A quick brown dog jumps over the lazy fox\"\n",
    "\n",
    "meteor_result = compute_meteor_score(reference_text, hypothesis_text)\n",
    "print(\"METEOR Result:\", meteor_result)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METEOR Result: {'recall': 0.2222222222222222, 'precision': 0.5, 'f1_score': 0.23529411764705882}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ROUGE-N\n",
    "n-gram(1-gram, 2-gram 등)을 생성하여 참조(reference)와 가설(hypothesis)의 겹침을 측정.\n",
    "Recall, Precision, F1-score를 계산:\n",
    "Recall: 겹치는 n-gram / 참조 n-gram\n",
    "Precision: 겹치는 n-gram / 가설 n-gram\n",
    "F1: Recall과 Precision의 조화 평균."
   ],
   "id": "e7da09740040aad1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:11:43.333143Z",
     "start_time": "2024-12-02T03:11:43.324452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "from itertools import islice\n",
    "\n",
    "def get_ngrams(text, n):\n",
    "    \"\"\"\n",
    "    Generate n-grams from text.\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    return list(zip(*[tokens[i:] for i in range(n)]))\n",
    "\n",
    "def rouge_n(reference, hypothesis, n=1):\n",
    "    \"\"\"\n",
    "    Compute ROUGE-N score.\n",
    "    \"\"\"\n",
    "    # Generate n-grams for reference and hypothesis\n",
    "    ref_ngrams = Counter(get_ngrams(reference, n))\n",
    "    hyp_ngrams = Counter(get_ngrams(hypothesis, n))\n",
    "\n",
    "    # Count overlapping n-grams\n",
    "    overlap = sum((ref_ngrams & hyp_ngrams).values())\n",
    "    total_ref_ngrams = sum(ref_ngrams.values())\n",
    "    total_hyp_ngrams = sum(hyp_ngrams.values())\n",
    "\n",
    "    # Calculate Recall, Precision, and F1-score\n",
    "    recall = overlap / total_ref_ngrams if total_ref_ngrams > 0 else 0\n",
    "    precision = overlap / total_hyp_ngrams if total_hyp_ngrams > 0 else 0\n",
    "    f1_score = (2 * recall * precision / (recall + precision)) if (recall + precision) > 0 else 0\n",
    "\n",
    "    return {\"recall\": recall, \"precision\": precision, \"f1_score\": f1_score}\n",
    "\n",
    "# Example usage\n",
    "reference = \"the cat sat on the mat\"\n",
    "hypothesis = \"the cat is on the mat\"\n",
    "\n",
    "rouge_1 = rouge_n(reference, hypothesis, n=1)\n",
    "rouge_2 = rouge_n(reference, hypothesis, n=2)\n",
    "\n",
    "print(\"ROUGE-1:\", rouge_1)\n",
    "print(\"ROUGE-2:\", rouge_2)\n"
   ],
   "id": "16d1200b5804437d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: {'recall': 0.8333333333333334, 'precision': 0.8333333333333334, 'f1_score': 0.8333333333333334}\n",
      "ROUGE-2: {'recall': 0.6, 'precision': 0.6, 'f1_score': 0.6}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ROUGE-L\n",
    "\n",
    "LCS(Longest Common Subsequence)를 사용해 두 텍스트 간의 겹침을 측정.\n",
    "LCS 길이를 기반으로 Recall, Precision, F1-score 계산:\n",
    "Recall: LCS 길이 / 참조 단어 수\n",
    "Precision: LCS 길이 / 가설 단어 수."
   ],
   "id": "81c243bd7e7aedd7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:11:58.438916Z",
     "start_time": "2024-12-02T03:11:58.430601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def lcs_length(x, y):\n",
    "    \"\"\"\n",
    "    Compute the length of the Longest Common Subsequence (LCS).\n",
    "    \"\"\"\n",
    "    m, n = len(x), len(y)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if x[i - 1] == y[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "\n",
    "    return dp[m][n]\n",
    "\n",
    "def rouge_l(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    Compute ROUGE-L score.\n",
    "    \"\"\"\n",
    "    ref_tokens = reference.split()\n",
    "    hyp_tokens = hypothesis.split()\n",
    "\n",
    "    # Length of LCS\n",
    "    lcs = lcs_length(ref_tokens, hyp_tokens)\n",
    "\n",
    "    # Calculate Recall, Precision, and F1-score\n",
    "    recall = lcs / len(ref_tokens) if len(ref_tokens) > 0 else 0\n",
    "    precision = lcs / len(hyp_tokens) if len(hyp_tokens) > 0 else 0\n",
    "    f1_score = (2 * recall * precision / (recall + precision)) if (recall + precision) > 0 else 0\n",
    "\n",
    "    return {\"recall\": recall, \"precision\": precision, \"f1_score\": f1_score}\n",
    "\n",
    "# Example usage\n",
    "reference = \"the cat sat on the mat\"\n",
    "hypothesis = \"the cat is on the mat\"\n",
    "\n",
    "rouge_l_score = rouge_l(reference, hypothesis)\n",
    "\n",
    "print(\"ROUGE-L:\", rouge_l_score)\n"
   ],
   "id": "dd4b524724f77098",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-L: {'recall': 0.8333333333333334, 'precision': 0.8333333333333334, 'f1_score': 0.8333333333333334}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  BERTScore 예제",
   "id": "7c8abadfb1bf7e7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T11:38:36.493331Z",
     "start_time": "2024-12-04T11:38:35.343860Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install bert-score",
   "id": "a81b56320a76f3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-score in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from bert-score) (2.5.1+cu124)\n",
      "Requirement already satisfied: pandas>=1.0.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from bert-score) (2.2.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from bert-score) (4.46.3)\n",
      "Requirement already satisfied: numpy in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: requests in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from bert-score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from bert-score) (3.9.3)\n",
      "Requirement already satisfied: packaging>=20.9 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from bert-score) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
      "Requirement already satisfied: filelock in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: networkx in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: colorama in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from tqdm>=4.31.1->bert-score) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.26.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from matplotlib->bert-score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from matplotlib->bert-score) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from matplotlib->bert-score) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from matplotlib->bert-score) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from matplotlib->bert-score) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from requests->bert-score) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from requests->bert-score) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from requests->bert-score) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:39:33.109413Z",
     "start_time": "2024-12-02T03:39:22.227642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bert_score import score\n",
    "\n",
    "# 참조 텍스트와 생성 텍스트\n",
    "references = [\"빠른 갈색 여우가 게으른 개를 뛰어넘었다.\"]\n",
    "hypotheses = [\"빠른 갈색 여우가 게으른 개를 뛰어 넘었다.\"]\n",
    "\n",
    "# BERTScore 계산\n",
    "P, R, F1 = score(hypotheses, references, lang=\"ko\", verbose=True)\n",
    "\n",
    "print(f\"Precision: {P.mean().item():.4f}\")\n",
    "print(f\"Recall: {R.mean().item():.4f}\")\n",
    "print(f\"F1 Score: {F1.mean().item():.4f}\")\n"
   ],
   "id": "6bd1d545d8c998c7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\SKN\\Final\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 394.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.08 seconds, 12.02 sentences/sec\n",
      "Precision: 0.9588\n",
      "Recall: 0.9588\n",
      "F1 Score: 0.9588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# GPTScore (Perplexity 기반 평가)",
   "id": "d39a00307131f801"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T11:36:28.210105Z",
     "start_time": "2024-12-04T11:36:27.068480Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install transformers",
   "id": "35cfab4e91257751",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:40:48.637577Z",
     "start_time": "2024-12-02T03:40:37.830584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "\n",
    "def calculate_perplexity(model, tokenizer, text):\n",
    "    \"\"\"\n",
    "    Perplexity 계산 함수\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "    loss = outputs.loss\n",
    "    perplexity = torch.exp(loss)\n",
    "    return perplexity.item()\n",
    "\n",
    "# GPT-2 모델 로드\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# 텍스트 Perplexity 계산\n",
    "text = \"빠른 갈색 여우가 게으른 개를 뛰어넘었다.\"\n",
    "perplexity = calculate_perplexity(model, tokenizer, text)\n",
    "print(f\"Perplexity: {perplexity:.4f}\")\n"
   ],
   "id": "1ebf216011ec0116",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\SKN\\Final\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 9.4079\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Sentence Similarity with Cosine Similarity",
   "id": "a856988b814c5b5a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T11:37:48.816649Z",
     "start_time": "2024-12-04T11:37:47.603978Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install sentence-transformers\n",
   "id": "b0dbfe13a6ba4a03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from sentence-transformers) (2.5.1+cu124)\n",
      "Requirement already satisfied: scikit-learn in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from sentence-transformers) (0.26.3)\n",
      "Requirement already satisfied: Pillow in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T05:06:14.698956Z",
     "start_time": "2024-12-02T05:06:02.922111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 모델 로드\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# 텍스트 정의\n",
    "reference = \"빠른 갈색 여우가 게으른 개를 뛰어넘었다.\"\n",
    "hypothesis = \"빠른 갈색 여우가 게으른 개를 뛰어 넘었다.\"\n",
    "\n",
    "# 임베딩 생성\n",
    "ref_embedding = model.encode([reference])\n",
    "hyp_embedding = model.encode([hypothesis])\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "similarity = cosine_similarity(ref_embedding, hyp_embedding)\n",
    "print(f\"Cosine Similarity: {similarity[0][0]:.4f}\")\n"
   ],
   "id": "1cb050842c6957e3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\SKN\\Final\\SKN03-FINAL-6Team\\TailorLink_LLM\\doc_retrieval_qa\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9863\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "89006419ddda66ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# G-EVAL",
   "id": "a256bbee2eb871a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T11:40:37.684458Z",
     "start_time": "2024-12-04T11:40:36.518561Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install openai\n",
   "id": "2cebb66a730c1a38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (1.55.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from openai) (0.28.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from openai) (2.10.2)\n",
      "Requirement already satisfied: sniffio in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: colorama in e:\\tailorlink\\skn03-final-6team\\tailorlink_llm\\doc_retrieval_qa\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T05:59:17.859757Z",
     "start_time": "2024-12-02T05:59:12.933923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "# OpenAI API 키 설정\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"\"\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "def g_eval(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    G-EVAL: GPT 기반 텍스트 평가\n",
    "    - reference: 기준 텍스트\n",
    "    - hypothesis: 평가할 텍스트\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert evaluator for language models. Please evaluate the following two texts:\n",
    "\n",
    "    Reference Text: \"{reference}\"\n",
    "    Hypothesis Text: \"{hypothesis}\"\n",
    "\n",
    "    Provide a similarity score between 0 and 100, where:\n",
    "    - 0 means the texts are completely different.\n",
    "    - 100 means the texts are identical in meaning and language quality.\n",
    "\n",
    "    Please briefly explain in Korean the reasoning behind your score.\n",
    "    \"\"\"\n",
    "    # 새로운 Chat API 호출\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # 모델 선택 (gpt-4 또는 gpt-3.5-turbo)\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # GPT의 응답에서 메시지 내용 추출\n",
    "    gpt_response = completion.choices[0].message.content\n",
    "    return gpt_response\n",
    "\n",
    "# 테스트 데이터\n",
    "reference_text = \"빠른 갈색 여우가 게으른 개를 뛰어넘었다.\"\n",
    "hypothesis_text = \"게으른 늙은 여우가 게으른 개를 뛰어 넘었다.\"\n",
    "\n",
    "# G-EVAL 결과\n",
    "result = g_eval(reference_text, hypothesis_text)\n",
    "print(\"G-EVAL 결과:\")\n",
    "print(result)\n",
    "\n"
   ],
   "id": "c97688fa66909c4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G-EVAL 결과:\n",
      "Similarity Score: 30\n",
      "\n",
      "두 텍스트 간의 유사성은 낮습니다. 두 문장 모두 비슷한 구조를 가지고 있지만, 내용에 중요한 차이가 있습니다. \n",
      "\n",
      "1. **주어의 차이**: Reference Text에서는 \"빠른 갈색 여우\"라는 주어가 사용되었고, Hypothesis Text에서는 \"게으른 늙은 여우\"라는 다른 주어가 사용되었습니다. 이로 인해 주어의 성격이 완전히 달라집니다.\n",
      "2. **형용사의 차이**: 두 텍스트에서 여우에 대한 형용사가 다르며, 이는 문장의 의미에 영향을 미칩니다. \"빠른\"과 \"게으른\"은 상반되는 의미를 전달합니다.\n",
      "3. ** 행동은 유사하지만**: 두 문장 모두 \"뛰어넘었다\"는 행동을 포함하지만, 주어의 차이로 인해 상황의 맥락이 다릅니다.\n",
      "\n",
      "따라서 두 문장은 비슷한 구조를 가지지만, 의미적으로는 상당한 차이가 있으므로 30점으로 평가했습니다.\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T12:35:38.698758Z",
     "start_time": "2024-12-04T12:35:38.694769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "5a7d3ac8c43e6602",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T12:35:46.277669Z",
     "start_time": "2024-12-04T12:35:39.416270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from evaluation import evaluate_rag\n",
    "\n",
    "text1= '브레이크는 차량의 속도를 줄이거나 정지시키기 위해 사용하는 장치입니다. 브레이크 페달을 밟으면 제동력이 발생하여 차량의 속도가 감소하게 됩니다. 이 차량에는 디스크 브레이크가 장착되어 있으며, 브레이크 패드가 마모되면 소리가 나므로 점검과 교체가 필요합니다. 추가적으로, 엔진 브레이크는 물리적인 브레이크는 아니지만 엔진의 압축 압력으로 바퀴의 회전을 억제하여 제동력을 얻는 방식입니다. \\n\\n브레이크 시스템의 이상이 있을 경우 브레이크 경고등이 켜지며, 이 경우 안전한 장소에 차량을 정지시키고 점검을 받아야 합니다.'\n",
    "\n",
    "text2= '브레이크는 차량의 속도를 줄이거나 정지시키기 위해 사용되는 장치입니다. 물리적인 브레이크 외에도 엔진 브레이크라는 개념이 있으며, 이는 엔진의 압축 압력으로 바퀴의 회전을 억제하여 제동력을 얻는 방법입니다. 브레이크 시스템은 안전한 주행을 위해 매우 중요하며, 적절한 점검과 유지 관리가 필요합니다.'\n",
    "\n",
    "evaluate_rag(text1, text2, True, False)"
   ],
   "id": "743dc07fa14a6330",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.14 seconds, 7.20 sentences/sec\n",
      "Precision: 0.8496\n",
      "Recall: 0.8047\n",
      "F1 Score: 0.8265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'METEOR': {'recall': 0.36507936507936506,\n",
       "  'precision': 0.6216216216216216,\n",
       "  'f1_score': 0.3807947019867549},\n",
       " 'ROUGE-1': {'recall': 0.36507936507936506,\n",
       "  'precision': 0.6216216216216216,\n",
       "  'f1_score': 0.46},\n",
       " 'ROUGE-L': {'recall': 0.30158730158730157,\n",
       "  'precision': 0.5135135135135135,\n",
       "  'f1_score': 0.37999999999999995},\n",
       " 'BERTScore': {'recall': 0.8047001957893372,\n",
       "  'precision': 0.849564254283905,\n",
       "  'f1_score': 0.8265239000320435},\n",
       " 'Cosine Similarity': {'Cosine Similarity': 0.9384466},\n",
       " 'G-EVAL': 'Similarity Score: 85\\n\\n이 두 텍스트는 내용적으로 매우 유사하지만, 약간의 차이가 있습니다. 두 텍스트 모두 브레이크의 기능과 타입(물리적인 브레이크와 엔진 브레이크)에 대해 설명하고 있으며, 브레이크 시스템의 중요성에 대해서도 언급하고 있습니다. 그러나 가벼운 문체와 표현의 차이가 있긴 합니다. 예를 들어, 가설 텍스트에서는 \"적절한 점검과 유지 관리가 필요하다\"는 문장이 포함되어 있지만, 참고 텍스트에서는 그와 같은 직접적인 언급이 없습니다. 이러한 차이에도 불구하고 두 텍스트의 기본적인 의미에는 큰 차이가 없으므로 85점을 주었습니다.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4f44ef35a3be0ec3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
